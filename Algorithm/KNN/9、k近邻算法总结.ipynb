{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、k近邻算法作用\n",
    "## 解决分类问题的算法，天然可以解决多分类问题\n",
    "    * 判别数据属于哪一类distance\n",
    "    * sklearn.KNeighborsClassifier类\n",
    "## 解决回归问题\n",
    "    * 预测数据的走向\n",
    "    * sklearn.KNeighborsRegressor类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、最大的缺点：\n",
    "* 效率低下\n",
    "    如果训练集有m个样本，n个特征，则预测每一个数据需要O（m*n） 的数据复杂度\n",
    "* 高度数据相关，对outliner更加敏感\n",
    "* 预测的结果不具有可解释性，只是拿到预测结果，而不能解释为什么\n",
    "* 维数灾难\n",
    "    随着维度的增加，看似相近的两个点之间的距离越来越大，解决办法：降维！\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、过程\n",
    "## 将一个数据集分位训练数据集和测试数据集train_test_split\n",
    "## 将训练数据集特征数据和测试数据集进行归一化StandardScalar\n",
    "## 对归一化的数据进行分类K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
